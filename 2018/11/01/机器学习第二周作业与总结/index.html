<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="孙远博, sybapp@qq.com"><title>机器学习第二周作业与总结 · 不将就 | 一个计算机小白的博客</title><meta name="description" content="第二周周问题
特征归一化方法（线性归一化，零均值归一化）的操作方法和优缺点

利用sklearn.preprocessing.PolynomialFeatures生成交叉特征


我的答案：归一化方法（Normalization Method）特点：
把数变为（0，1）之间的小数
有量纲表达式变为无"><meta name="keywords" content="Hexo, HTML, CSS, Android, Linux, WEB"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title><a href="/">不将就 | 一个计算机小白的博客</a></h3><div class="description"><p>一个计算机小白的博客 C / Python / Android / Linux / WEB</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/ansgsy"><i class="fa fa-weibo"></i></a></li><li><a href="http://github.com/sybapp"><i class="fa fa-github"></i></a></li></ul><div class="footer"><div class="by_farbox"><a href="https://sybapp.tk/" target="_blank">&#169 2018 不将就 All rights reserved. &#160;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>机器学习第二周作业与总结</a></h3></div><div class="post-content"><h2 id="第二周周问题"><a href="#第二周周问题" class="headerlink" title="第二周周问题"></a>第二周周问题</h2><ol>
<li><p>特征归一化方法（线性归一化，零均值归一化）的操作方法和优缺点</p>
</li>
<li><p>利用sklearn.preprocessing.PolynomialFeatures生成交叉特征</p>
</li>
</ol>
<h2 id="我的答案："><a href="#我的答案：" class="headerlink" title="我的答案："></a>我的答案：</h2><h2 id="归一化方法（Normalization-Method）"><a href="#归一化方法（Normalization-Method）" class="headerlink" title="归一化方法（Normalization Method）"></a><strong>归一化方法（Normalization Method）</strong></h2><h3 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h3><ol>
<li>把数变为（0，1）之间的小数</li>
<li>有量纲表达式变为无量纲表达式</li>
</ol>
<hr>
<h4 id="1-线性归一化（归一化）："><a href="#1-线性归一化（归一化）：" class="headerlink" title="1. 线性归一化（归一化）："></a>1. 线性归一化（归一化）：</h4><h5 id="操作方法："><a href="#操作方法：" class="headerlink" title="操作方法："></a>操作方法：</h5><p>$$<br>x’ = \frac{x - min(x)}{max(x) - min(x)}<br>$$</p>
<h6 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h6><ul>
<li>提高迭代求解的收敛速度</li>
<li>提高迭代求解的精度</li>
<li>深度学习中数据归一化可以防止模型梯度爆炸。</li>
</ul>
<h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><ul>
<li>由于极值化方法在对变量无量纲化过程中仅仅与该变量的最大值和最小值这两个极端 值有关，而与其他取值无关，这使得该方法在改变各变量权重时过分依赖两个极端取值。 </li>
</ul>
<h4 id="2-零均值归一化（标准化，中心化）："><a href="#2-零均值归一化（标准化，中心化）：" class="headerlink" title="2. 零均值归一化（标准化，中心化）："></a>2. 零均值归一化（标准化，中心化）：</h4><h5 id="操作方法：-1"><a href="#操作方法：-1" class="headerlink" title="操作方法："></a>操作方法：</h5><ul>
<li>将原始数据均映射到均值为0，标准差为1的分布上。具体来说，假设原始特征的均值为μ、标准差为σ，那么归一化公式定义为：</li>
</ul>
<p>$$<br>x’ = \frac{x - μ}{σ}<br>$$</p>
<ul>
<li>数据的标准化是将数据按比例缩放，使之落入一个小的特定区间。由于信用指标体系的各个指标度量单位是不同的，为了能够将指标参与评价计算，需要对指标进行规范化处理，通过函数变换将其数值映射到某个数值区间。</li>
</ul>
<h6 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a>优点：</h6><ul>
<li>不改变原始数据的分布</li>
</ul>
<h5 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h5><ul>
<li>这种归一化方式要求原始数据的分布可以近似为高斯分布，否则归一化的效果会变得很糟糕。 </li>
</ul>
<h2 id="sklearn-preprocessing-PolynomialFeatures生成交叉特征"><a href="#sklearn-preprocessing-PolynomialFeatures生成交叉特征" class="headerlink" title="sklearn.preprocessing.PolynomialFeatures生成交叉特征"></a>sklearn.preprocessing.PolynomialFeatures生成交叉特征</h2><p>在机器学习中，通过增加一些输入数据的非线性特征来增加模型的复杂度通常是有效的。一个简单通用的办法是使用多项式特征，这可以获得特征的更高维度和互相间关系的项。这在 PolynomialFeatures 中实现:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = np.arange(<span class="number">6</span>).reshape(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[0, 1],</span><br><span class="line">       [2, 3],</span><br><span class="line">       [4, 5]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Init signature: PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)</span></span><br><span class="line"><span class="comment"># Docstring:     </span></span><br><span class="line"><span class="comment"># Generate polynomial and interaction features.</span></span><br><span class="line"></span><br><span class="line">poly = PolynomialFeatures()</span><br><span class="line">poly.fit_transform(X)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[ 1.,  0.,  1.,  0.,  0.,  1.],</span><br><span class="line">       [ 1.,  2.,  3.,  4.,  6.,  9.],</span><br><span class="line">       [ 1.,  4.,  5., 16., 20., 25.]])</span><br></pre></td></tr></table></figure>
<p>$$<br>X 的特征已经从 (X_1, X_2) 转换为 (1, X_1, X_2, X_1^2, X_1X_2, X_2^2)。<br>在一些情况下，只需要特征间的交互项，这可以通过设置 interaction_only=True 来得到:<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">X</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[0, 1, 2],</span><br><span class="line">       [3, 4, 5],</span><br><span class="line">       [6, 7, 8]])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(degree=<span class="number">3</span>, interaction_only=<span class="literal">True</span>)</span><br><span class="line">poly.fit_transform(X)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array([[  1.,   0.,   1.,   2.,   0.,   0.,   2.,   0.],</span><br><span class="line">       [  1.,   3.,   4.,   5.,  12.,  15.,  20.,  60.],</span><br><span class="line">       [  1.,   6.,   7.,   8.,  42.,  48.,  56., 336.]])</span><br></pre></td></tr></table></figure>
<p>$$<br>X的特征已经从 (X_1, X_2, X_3) 转换为 (1, X_1, X_2, X_3, X_1X_2, X_1X_3, X_2X_3, X_1X_2X_3) 。<br>$$</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-11-01</span><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,https://sybapp.tk/2018/11/01/机器学习第二周作业与总结/,不将就 | 一个计算机小白的博客,机器学习第二周作业与总结,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2019/08/01/Luckymoney-初个SpringBoot项目/" title="Luckymoney--初个SpringBoot项目">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2018/10/22/机器学习第一周作业与总结/" title="机器学习第一周作业与总结">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>
<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="孙远博, sybapp@qq.com"><title>使用Selenium爬取淘宝商品并存入MongoDB数据库 · 不将就 | 一个计算机小白的博客</title><meta name="description" content="使用Selenium爬取淘宝商品并存入MongoDB数据库使用库
Selenium
pymongo
BeautifulSoup

代码使用了Chrome的无界面浏览模式抓取的淘宝商品数据
数据包括：

名称
链接     
图片
价格
店铺
地区
付款人数

12345678910111213141"><meta name="keywords" content="Hexo, HTML, CSS, Android, Linux, WEB"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title><a href="/">不将就 | 一个计算机小白的博客</a></h3><div class="description"><p>一个计算机小白的博客 C / Python / Android / Linux / WEB</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/ansgsy"><i class="fa fa-weibo"></i></a></li><li><a href="http://github.com/sybapp"><i class="fa fa-github"></i></a></li></ul><div class="footer"><div class="by_farbox"><a href="https://sybapp.tk/" target="_blank">&#169 2018 不将就 All rights reserved. &#160;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>使用Selenium爬取淘宝商品并存入MongoDB数据库</a></h3></div><div class="post-content"><h2 id="使用Selenium爬取淘宝商品并存入MongoDB数据库"><a href="#使用Selenium爬取淘宝商品并存入MongoDB数据库" class="headerlink" title="使用Selenium爬取淘宝商品并存入MongoDB数据库"></a>使用Selenium爬取淘宝商品并存入MongoDB数据库</h2><h3 id="使用库"><a href="#使用库" class="headerlink" title="使用库"></a>使用库</h3><ul>
<li>Selenium</li>
<li>pymongo</li>
<li>BeautifulSoup</li>
</ul>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>使用了Chrome的无界面浏览模式抓取的淘宝商品数据</p>
<p>数据包括：</p>
<ul>
<li>名称</li>
<li>链接     </li>
<li>图片</li>
<li>价格</li>
<li>店铺</li>
<li>地区</li>
<li>付款人数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.wait <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> selenium.common.exceptions <span class="keyword">import</span> TimeoutException</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">keywords = <span class="string">'iPhone'</span></span><br><span class="line"></span><br><span class="line">chrome_options = webdriver.ChromeOptions()</span><br><span class="line">chrome_options.add_argument(<span class="string">'--headless'</span>)</span><br><span class="line">chrome_options.add_argument(<span class="string">'--disable-gpu'</span>)</span><br><span class="line">driver = webdriver.Chrome(chrome_options=chrome_options)</span><br><span class="line">wait = WebDriverWait(driver, <span class="number">10</span>)</span><br><span class="line">base_url = <span class="string">'https://s.taobao.com/search?q='</span></span><br><span class="line">url = base_url + quote(keywords)</span><br><span class="line">driver.get(url)</span><br><span class="line"></span><br><span class="line">client = pymongo.MongoClient(<span class="string">'localhost'</span>)</span><br><span class="line">db = client[<span class="string">'Taobao'</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_page</span><span class="params">(page)</span>:</span></span><br><span class="line">    print(<span class="string">'正在请求第'</span>, page, <span class="string">'页'</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        input = wait.until(</span><br><span class="line">            EC.presence_of_element_located(</span><br><span class="line">                (By.CSS_SELECTOR, <span class="string">'#mainsrp-pager div.form &gt; input'</span>)))</span><br><span class="line">        input.clear()</span><br><span class="line">        input.send_keys(page)</span><br><span class="line">        submit = wait.until(</span><br><span class="line">            EC.element_to_be_clickable(</span><br><span class="line">                (By.CSS_SELECTOR, <span class="string">'#mainsrp-pager div.form &gt; span.btn.J_Submit'</span>)))</span><br><span class="line">        submit.click()</span><br><span class="line">        wait.until(EC.text_to_be_present_in_element(</span><br><span class="line">            (By.CSS_SELECTOR, <span class="string">'#mainsrp-pager li.item.active &gt; span'</span>), str(page)))</span><br><span class="line">        print(<span class="string">'已到达'</span>, page, <span class="string">'页'</span>)</span><br><span class="line">        wait.until(EC.presence_of_element_located(</span><br><span class="line">            (By.CSS_SELECTOR, <span class="string">'.m-itemlist'</span>)))</span><br><span class="line">        print(<span class="string">'正在抓取···'</span>)</span><br><span class="line">        dict = get_products(driver.page_source)</span><br><span class="line">        save_to_mongo(dict)</span><br><span class="line">    <span class="keyword">except</span> TimeoutException:</span><br><span class="line">        print(<span class="string">'请求第'</span>, page, <span class="string">'超时'</span>)</span><br><span class="line">        print(<span class="string">'正在重试···'</span>)</span><br><span class="line">        index_page(page)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_products</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    items = soup.select(<span class="string">'#mainsrp-itemlist .items .item'</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> items:</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">                link = item.select_one(<span class="string">'.J_ClickStat'</span>).attrs[<span class="string">'data-href'</span>]</span><br><span class="line">                <span class="keyword">if</span> link[:<span class="number">6</span>] == <span class="string">'https:'</span>:</span><br><span class="line">                    link = link[<span class="number">6</span>:]</span><br><span class="line">                dict = &#123;</span><br><span class="line">                    <span class="string">'名称'</span>: item.select_one(<span class="string">'.pic .J_ItemPic'</span>).attrs[<span class="string">'alt'</span>],</span><br><span class="line">                    <span class="string">'链接'</span>: <span class="string">'https:'</span> + link,</span><br><span class="line">                    <span class="string">'图片'</span>: <span class="string">'https:'</span> + item.select_one(<span class="string">'.pic-link .img'</span>).attrs[<span class="string">'data-src'</span>],</span><br><span class="line">                    <span class="string">'价格'</span>: item.select_one(<span class="string">'.price'</span>).get_text().strip(),</span><br><span class="line">                    <span class="string">'店铺'</span>: item.select_one(<span class="string">'.shop'</span>).get_text().strip(),</span><br><span class="line">                    <span class="string">'地区'</span>: item.select_one(<span class="string">'.location'</span>).get_text(),</span><br><span class="line">                    <span class="string">'付款人数'</span>: item.select_one(<span class="string">'.deal-cnt'</span>).get_text()[:<span class="number">-3</span>]</span><br><span class="line">                   &#125;</span><br><span class="line">                print(dict)</span><br><span class="line">                <span class="keyword">yield</span> dict</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        print(<span class="string">'爬取异常'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mongo</span><span class="params">(dict)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> db[<span class="string">'products'</span>].insert(dict):</span><br><span class="line">            print(<span class="string">'存储到MongoDB成功'</span>)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        print(<span class="string">'存储到MongoDB失败'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">101</span>):</span><br><span class="line">        index_page(page)</span><br><span class="line">    driver.close()</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/sybapp/TaoBao_Spider" target="_blank" rel="noopener">GitHub地址</a></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-07-31</span><i class="fa fa-tag"></i><a class="tag" href="/tags/Python-爬虫/" title="Python 爬虫">Python 爬虫 </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,https://sybapp.tk/2018/07/31/使用Selenium爬取淘宝商品并存入MongoDB数据库/,不将就 | 一个计算机小白的博客,使用Selenium爬取淘宝商品并存入MongoDB数据库,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2018/08/06/Pycharm-快捷键/" title="Pycharm 快捷键">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2018/07/19/抓取CSDN博客数据并存入MySQL数据库/" title="抓取CSDN博客数据并存入MySQL数据库">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>